{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Data Exploration\n",
    "\n",
    "**Customer Lifetime Value Prediction**\n",
    "\n",
    "**Team:** The Starks\n",
    "- Othmane Zizi (261255341)\n",
    "- Fares Joni (261254593)\n",
    "- Tanmay Giri (261272443)\n",
    "\n",
    "This notebook performs initial exploration of the Online Retail II dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load both sheets from the Excel file\n",
    "data_path = Path('../data/raw/online_retail_II.xlsx')\n",
    "\n",
    "print(\"Loading Year 2009-2010...\")\n",
    "df_2009_2010 = pd.read_excel(data_path, sheet_name='Year 2009-2010')\n",
    "print(f\"Shape: {df_2009_2010.shape}\")\n",
    "\n",
    "print(\"\\nLoading Year 2010-2011...\")\n",
    "df_2010_2011 = pd.read_excel(data_path, sheet_name='Year 2010-2011')\n",
    "print(f\"Shape: {df_2010_2011.shape}\")\n",
    "\n",
    "# Combine sheets\n",
    "df = pd.concat([df_2009_2010, df_2010_2011], ignore_index=True)\n",
    "print(f\"\\nCombined shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Data Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types and info\n",
    "print(\"Data Types:\")\n",
    "print(df.dtypes)\n",
    "print(f\"\\nMemory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Missing Values Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (df.isnull().sum() / len(df) * 100).round(2)\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing,\n",
    "    'Missing %': missing_pct\n",
    "})\n",
    "missing_df[missing_df['Missing Count'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize missing values\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "missing_pct[missing_pct > 0].plot(kind='bar', ax=ax, color='coral')\n",
    "ax.set_title('Missing Values by Column')\n",
    "ax.set_ylabel('Percentage Missing')\n",
    "ax.set_xlabel('Column')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/missing_values.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Date Range Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert InvoiceDate to datetime if not already\n",
    "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
    "\n",
    "print(f\"Date Range: {df['InvoiceDate'].min()} to {df['InvoiceDate'].max()}\")\n",
    "print(f\"Duration: {(df['InvoiceDate'].max() - df['InvoiceDate'].min()).days} days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transactions over time\n",
    "daily_transactions = df.groupby(df['InvoiceDate'].dt.date).size()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "daily_transactions.plot(ax=ax, alpha=0.7)\n",
    "ax.set_title('Daily Transaction Count Over Time')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Number of Transactions')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/daily_transactions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Customer Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows with Customer ID\n",
    "df_with_customer = df[df['Customer ID'].notna()].copy()\n",
    "df_with_customer['Customer ID'] = df_with_customer['Customer ID'].astype(int)\n",
    "\n",
    "print(f\"Total transactions: {len(df)}\")\n",
    "print(f\"Transactions with Customer ID: {len(df_with_customer)} ({len(df_with_customer)/len(df)*100:.1f}%)\")\n",
    "print(f\"Unique customers: {df_with_customer['Customer ID'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer purchase frequency distribution\n",
    "customer_freq = df_with_customer.groupby('Customer ID')['Invoice'].nunique()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(customer_freq, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_title('Customer Purchase Frequency Distribution')\n",
    "axes[0].set_xlabel('Number of Purchases')\n",
    "axes[0].set_ylabel('Number of Customers')\n",
    "axes[0].set_xlim(0, customer_freq.quantile(0.95))  # Focus on 95th percentile\n",
    "\n",
    "# Box plot\n",
    "axes[1].boxplot(customer_freq, vert=True)\n",
    "axes[1].set_title('Purchase Frequency Box Plot')\n",
    "axes[1].set_ylabel('Number of Purchases')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/customer_frequency.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nPurchase Frequency Statistics:\")\n",
    "print(customer_freq.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Country Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top countries by transaction count\n",
    "country_counts = df['Country'].value_counts()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "country_counts.head(15).plot(kind='bar', ax=ax, color='steelblue')\n",
    "ax.set_title('Top 15 Countries by Transaction Count')\n",
    "ax.set_xlabel('Country')\n",
    "ax.set_ylabel('Number of Transactions')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/top_countries.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nCountry Distribution:\")\n",
    "print(f\"UK transactions: {country_counts['United Kingdom']} ({country_counts['United Kingdom']/len(df)*100:.1f}%)\")\n",
    "print(f\"Non-UK transactions: {country_counts.sum() - country_counts['United Kingdom']} ({(1 - country_counts['United Kingdom']/len(df))*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Product Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Unique products (StockCode): {df['StockCode'].nunique()}\")\n",
    "print(f\"Unique descriptions: {df['Description'].nunique()}\")\n",
    "\n",
    "# Top selling products\n",
    "top_products = df.groupby(['StockCode', 'Description'])['Quantity'].sum().sort_values(ascending=False).head(10)\n",
    "print(\"\\nTop 10 Products by Quantity Sold:\")\n",
    "top_products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Price and Quantity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for negative values and cancelled transactions\n",
    "print(\"Quantity Analysis:\")\n",
    "print(f\"  Negative quantities: {(df['Quantity'] < 0).sum()} ({(df['Quantity'] < 0).mean()*100:.2f}%)\")\n",
    "print(f\"  Zero quantities: {(df['Quantity'] == 0).sum()}\")\n",
    "print(f\"  Positive quantities: {(df['Quantity'] > 0).sum()}\")\n",
    "\n",
    "print(\"\\nPrice Analysis:\")\n",
    "print(f\"  Zero or negative prices: {(df['Price'] <= 0).sum()} ({(df['Price'] <= 0).mean()*100:.2f}%)\")\n",
    "\n",
    "# Check cancelled transactions (Invoice starting with 'C')\n",
    "cancelled = df['Invoice'].astype(str).str.startswith('C')\n",
    "print(f\"\\nCancelled transactions: {cancelled.sum()} ({cancelled.mean()*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter valid transactions for price/quantity analysis\n",
    "df_valid = df[(df['Quantity'] > 0) & (df['Price'] > 0)].copy()\n",
    "df_valid['TotalAmount'] = df_valid['Quantity'] * df_valid['Price']\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Quantity distribution\n",
    "axes[0].hist(df_valid['Quantity'].clip(upper=df_valid['Quantity'].quantile(0.95)), \n",
    "             bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_title('Quantity Distribution (95th percentile)')\n",
    "axes[0].set_xlabel('Quantity')\n",
    "\n",
    "# Price distribution\n",
    "axes[1].hist(df_valid['Price'].clip(upper=df_valid['Price'].quantile(0.95)), \n",
    "             bins=50, edgecolor='black', alpha=0.7, color='green')\n",
    "axes[1].set_title('Price Distribution (95th percentile)')\n",
    "axes[1].set_xlabel('Price (GBP)')\n",
    "\n",
    "# Total Amount distribution\n",
    "axes[2].hist(df_valid['TotalAmount'].clip(upper=df_valid['TotalAmount'].quantile(0.95)), \n",
    "             bins=50, edgecolor='black', alpha=0.7, color='purple')\n",
    "axes[2].set_title('Total Amount Distribution (95th percentile)')\n",
    "axes[2].set_xlabel('Total Amount (GBP)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/price_quantity_dist.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary Statistics for Cleaned Data Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview of data after basic cleaning\n",
    "df_clean_preview = df[\n",
    "    (df['Customer ID'].notna()) & \n",
    "    (~df['Invoice'].astype(str).str.startswith('C')) &\n",
    "    (df['Quantity'] > 0) & \n",
    "    (df['Price'] > 0)\n",
    "].copy()\n",
    "\n",
    "print(\"Data Summary After Basic Cleaning Preview:\")\n",
    "print(f\"  Original rows: {len(df):,}\")\n",
    "print(f\"  Cleaned rows: {len(df_clean_preview):,} ({len(df_clean_preview)/len(df)*100:.1f}%)\")\n",
    "print(f\"  Unique customers: {df_clean_preview['Customer ID'].nunique():,}\")\n",
    "print(f\"  Unique invoices: {df_clean_preview['Invoice'].nunique():,}\")\n",
    "print(f\"  Date range: {df_clean_preview['InvoiceDate'].min().date()} to {df_clean_preview['InvoiceDate'].max().date()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Key Observations\n",
    "\n",
    "### Data Quality:\n",
    "- ~20% of records missing Customer ID - these will be removed\n",
    "- ~2% cancelled transactions (Invoice starts with 'C') - these will be removed\n",
    "- Some negative quantities exist (returns/cancellations)\n",
    "\n",
    "### Business Insights:\n",
    "- UK dominates the customer base (~90% of transactions)\n",
    "- Wide variation in purchase frequency across customers\n",
    "- Strong seasonality expected (retail business)\n",
    "\n",
    "### Next Steps:\n",
    "1. Clean the data (remove missing CustomerID, cancelled orders, negative values)\n",
    "2. Engineer RFM features\n",
    "3. Create train/test split based on time (observation vs prediction period)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
