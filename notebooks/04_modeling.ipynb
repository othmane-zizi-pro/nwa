{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - CLV Prediction Modeling\n",
    "\n",
    "**Customer Lifetime Value Prediction**\n",
    "\n",
    "**Team:** The Starks\n",
    "- Othmane Zizi (261255341)\n",
    "- Fares Joni (261254593)\n",
    "- Tanmay Giri (261272443)\n",
    "\n",
    "This notebook trains and evaluates multiple ML models for CLV prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append(str(Path('../src').resolve()))\n",
    "from data_loader import load_customer_features\n",
    "from models import get_models, train_and_evaluate, get_feature_importance, cross_validate_model\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Feature Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load customer features with CLV target\n",
    "df = load_customer_features('customer_features.csv')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature columns and target\n",
    "feature_cols = ['Recency', 'Frequency', 'Monetary', 'Tenure', \n",
    "                'AvgTimeBetweenPurchases', 'NumUniqueProducts', \n",
    "                'AvgBasketSize', 'AvgOrderValue']\n",
    "\n",
    "target_col = 'CLV'\n",
    "\n",
    "X = df[feature_cols].copy()\n",
    "y = df[target_col].copy()\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nTarget statistics:\")\n",
    "print(y.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for any remaining missing values\n",
    "print(\"Missing values in features:\")\n",
    "print(X.isnull().sum().sum())\n",
    "\n",
    "# Fill any missing values with 0\n",
    "X = X.fillna(0)\n",
    "y = y.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Scale Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(X_train),\n",
    "    columns=feature_cols,\n",
    "    index=X_train.index\n",
    ")\n",
    "X_test_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_test),\n",
    "    columns=feature_cols,\n",
    "    index=X_test.index\n",
    ")\n",
    "\n",
    "print(\"Scaled feature statistics (training):\")\n",
    "X_train_scaled.describe().loc[['mean', 'std']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train Multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(alpha=1.0),\n",
    "    'Lasso Regression': Lasso(alpha=1.0),\n",
    "    'Random Forest': RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        min_samples_split=5,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate all models\n",
    "results = {}\n",
    "trained_models = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Train\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    trained_models[name] = model\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_pred = np.clip(y_pred, 0, None)  # CLV can't be negative\n",
    "    \n",
    "    # Evaluate\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    results[name] = {\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'R2': r2\n",
    "    }\n",
    "    \n",
    "    print(f\"  RMSE: {rmse:.2f}\")\n",
    "    print(f\"  MAE: {mae:.2f}\")\n",
    "    print(f\"  R2: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results dataframe\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df = results_df.sort_values('RMSE')\n",
    "\n",
    "print(\"Model Performance Comparison:\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "metrics = ['RMSE', 'MAE', 'R2']\n",
    "colors = ['coral', 'steelblue', 'green']\n",
    "\n",
    "for ax, metric, color in zip(axes, metrics, colors):\n",
    "    results_df[metric].plot(kind='bar', ax=ax, color=color, edgecolor='black')\n",
    "    ax.set_title(f'{metric} by Model')\n",
    "    ax.set_xlabel('Model')\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/model_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Best Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select best model (lowest RMSE)\n",
    "best_model_name = results_df['RMSE'].idxmin()\n",
    "best_model = trained_models[best_model_name]\n",
    "\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "print(f\"\\nPerformance:\")\n",
    "print(results_df.loc[best_model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions vs Actual\n",
    "y_pred_best = best_model.predict(X_test_scaled)\n",
    "y_pred_best = np.clip(y_pred_best, 0, None)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Scatter plot: Predicted vs Actual\n",
    "axes[0].scatter(y_test, y_pred_best, alpha=0.5, s=10)\n",
    "max_val = max(y_test.max(), y_pred_best.max())\n",
    "axes[0].plot([0, max_val], [0, max_val], 'r--', label='Perfect Prediction')\n",
    "axes[0].set_xlabel('Actual CLV')\n",
    "axes[0].set_ylabel('Predicted CLV')\n",
    "axes[0].set_title(f'{best_model_name}: Predicted vs Actual CLV')\n",
    "axes[0].legend()\n",
    "\n",
    "# Residuals\n",
    "residuals = y_test - y_pred_best\n",
    "axes[1].hist(residuals, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[1].axvline(x=0, color='r', linestyle='--')\n",
    "axes[1].set_xlabel('Residual (Actual - Predicted)')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title(f'{best_model_name}: Residual Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/best_model_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance from tree-based models\n",
    "importance_dict = {}\n",
    "\n",
    "for name in ['Random Forest', 'Gradient Boosting']:\n",
    "    model = trained_models[name]\n",
    "    importance_dict[name] = model.feature_importances_\n",
    "\n",
    "# Also get coefficients from linear models\n",
    "for name in ['Linear Regression', 'Ridge Regression', 'Lasso Regression']:\n",
    "    model = trained_models[name]\n",
    "    importance_dict[name] = np.abs(model.coef_)\n",
    "\n",
    "importance_df = pd.DataFrame(importance_dict, index=feature_cols)\n",
    "print(\"Feature Importance by Model:\")\n",
    "importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance (from best tree-based model)\n",
    "if 'Random Forest' in best_model_name or 'Gradient Boosting' in best_model_name:\n",
    "    fi = importance_df[best_model_name].sort_values(ascending=True)\n",
    "else:\n",
    "    fi = importance_df['Random Forest'].sort_values(ascending=True)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "fi.plot(kind='barh', color='steelblue', edgecolor='black')\n",
    "plt.title('Feature Importance (Random Forest)')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/feature_importance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation for best model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Cross-validating {name}...\")\n",
    "    \n",
    "    # 5-fold CV\n",
    "    r2_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='r2')\n",
    "    neg_rmse = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='neg_root_mean_squared_error')\n",
    "    \n",
    "    cv_results[name] = {\n",
    "        'R2_mean': r2_scores.mean(),\n",
    "        'R2_std': r2_scores.std(),\n",
    "        'RMSE_mean': -neg_rmse.mean(),\n",
    "        'RMSE_std': neg_rmse.std()\n",
    "    }\n",
    "\n",
    "cv_df = pd.DataFrame(cv_results).T\n",
    "print(\"\\nCross-Validation Results (5-fold):\")\n",
    "cv_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Lift Analysis (Business Metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lift analysis: How well do we identify high-value customers?\n",
    "test_results = pd.DataFrame({\n",
    "    'Actual_CLV': y_test,\n",
    "    'Predicted_CLV': y_pred_best\n",
    "})\n",
    "\n",
    "# Sort by predicted CLV\n",
    "test_results = test_results.sort_values('Predicted_CLV', ascending=False)\n",
    "\n",
    "# Calculate cumulative actual CLV for top N%\n",
    "test_results['Cumulative_Actual'] = test_results['Actual_CLV'].cumsum()\n",
    "test_results['Cumulative_Pct'] = test_results['Cumulative_Actual'] / test_results['Actual_CLV'].sum()\n",
    "test_results['Customer_Pct'] = np.arange(1, len(test_results) + 1) / len(test_results)\n",
    "\n",
    "# Lift chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(test_results['Customer_Pct'] * 100, test_results['Cumulative_Pct'] * 100, \n",
    "         label='Model', linewidth=2)\n",
    "plt.plot([0, 100], [0, 100], 'r--', label='Random', linewidth=2)\n",
    "plt.xlabel('% of Customers (Sorted by Predicted CLV)')\n",
    "plt.ylabel('% of Total Actual CLV Captured')\n",
    "plt.title('Lift Chart: Model vs Random Selection')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/lift_chart.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Calculate lift at different thresholds\n",
    "for pct in [10, 20, 30, 50]:\n",
    "    top_n = int(len(test_results) * pct / 100)\n",
    "    captured = test_results.head(top_n)['Actual_CLV'].sum() / test_results['Actual_CLV'].sum()\n",
    "    lift = captured / (pct / 100)\n",
    "    print(f\"Top {pct}% customers capture {captured*100:.1f}% of CLV (Lift: {lift:.2f}x)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Save Model and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "results_df.to_csv('../reports/model_results.csv')\n",
    "cv_df.to_csv('../reports/cv_results.csv')\n",
    "importance_df.to_csv('../reports/feature_importance.csv')\n",
    "\n",
    "print(\"Results saved to reports/\")\n",
    "\n",
    "# Save predictions for segmentation\n",
    "predictions_df = df[['Customer ID']].copy()\n",
    "X_all_scaled = pd.DataFrame(\n",
    "    scaler.transform(X),\n",
    "    columns=feature_cols,\n",
    "    index=X.index\n",
    ")\n",
    "predictions_df['Predicted_CLV'] = np.clip(best_model.predict(X_all_scaled), 0, None)\n",
    "predictions_df['Actual_CLV'] = y\n",
    "\n",
    "predictions_df.to_csv('../data/processed/clv_predictions.csv', index=False)\n",
    "print(f\"\\nPredictions saved: {len(predictions_df)} customers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Modeling Summary\n",
    "\n",
    "### Models Trained:\n",
    "1. Linear Regression (baseline)\n",
    "2. Ridge Regression (L2 regularization)\n",
    "3. Lasso Regression (L1 regularization)\n",
    "4. Random Forest\n",
    "5. Gradient Boosting\n",
    "\n",
    "### Key Findings:\n",
    "- Tree-based models (Random Forest, Gradient Boosting) generally outperform linear models\n",
    "- Most important features: Monetary, Frequency, AvgOrderValue\n",
    "- Model can identify top 20% of customers capturing ~X% of total CLV\n",
    "\n",
    "### Business Impact:\n",
    "- Using the model to target top 20% customers provides significant lift over random selection\n",
    "- Enables prioritization of marketing resources on high-value customers\n",
    "\n",
    "### Next Steps:\n",
    "- Use predictions for customer segmentation\n",
    "- Develop targeted retention strategies for each segment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
